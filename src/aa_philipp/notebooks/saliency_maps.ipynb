{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4db0c392",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../..')\n",
    "sys.path.insert(0, '../../..')\n",
    "sys.path.insert(0, '../../../..')\n",
    "\n",
    "from model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model import DropoutUncertaintyEncoderDecoderLSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b8fd35",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "75cff575",
   "metadata": {},
   "source": [
    "# *** This Notebook is not yet functional ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de294e50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set categories:  ([('Activity', 16, {'Assign seriousness': 1, 'Closed': 2, 'Create SW anomaly': 3, 'DUPLICATE': 4, 'EOS': 5, 'INVALID': 6, 'Insert ticket': 7, 'RESOLVED': 8, 'Require upgrade': 9, 'Resolve SW anomaly': 10, 'Resolve ticket': 11, 'Schedule intervention': 12, 'Take in charge ticket': 13, 'VERIFIED': 14, 'Wait': 15}), ('Resource', 24, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 22': 16, 'Value 3': 17, 'Value 4': 18, 'Value 5': 19, 'Value 6': 20, 'Value 7': 21, 'Value 8': 22, 'Value 9': 23}), ('VariantIndex', 175, {'1.0': 1, '10.0': 2, '100.0': 3, '103.0': 4, '104.0': 5, '107.0': 6, '109.0': 7, '11.0': 8, '110.0': 9, '112.0': 10, '113.0': 11, '114.0': 12, '115.0': 13, '117.0': 14, '118.0': 15, '12.0': 16, '120.0': 17, '122.0': 18, '123.0': 19, '124.0': 20, '125.0': 21, '126.0': 22, '127.0': 23, '129.0': 24, '13.0': 25, '130.0': 26, '131.0': 27, '134.0': 28, '135.0': 29, '137.0': 30, '138.0': 31, '139.0': 32, '14.0': 33, '140.0': 34, '141.0': 35, '143.0': 36, '145.0': 37, '147.0': 38, '149.0': 39, '15.0': 40, '150.0': 41, '151.0': 42, '152.0': 43, '153.0': 44, '154.0': 45, '155.0': 46, '156.0': 47, '157.0': 48, '158.0': 49, '16.0': 50, '162.0': 51, '163.0': 52, '164.0': 53, '165.0': 54, '167.0': 55, '168.0': 56, '169.0': 57, '17.0': 58, '170.0': 59, '172.0': 60, '173.0': 61, '175.0': 62, '176.0': 63, '179.0': 64, '18.0': 65, '180.0': 66, '181.0': 67, '182.0': 68, '183.0': 69, '188.0': 70, '19.0': 71, '192.0': 72, '193.0': 73, '194.0': 74, '195.0': 75, '197.0': 76, '199.0': 77, '2.0': 78, '20.0': 79, '202.0': 80, '203.0': 81, '204.0': 82, '205.0': 83, '207.0': 84, '208.0': 85, '21.0': 86, '211.0': 87, '212.0': 88, '214.0': 89, '217.0': 90, '22.0': 91, '220.0': 92, '222.0': 93, '225.0': 94, '23.0': 95, '24.0': 96, '25.0': 97, '26.0': 98, '27.0': 99, '28.0': 100, '29.0': 101, '3.0': 102, '30.0': 103, '31.0': 104, '32.0': 105, '33.0': 106, '34.0': 107, '35.0': 108, '36.0': 109, '37.0': 110, '38.0': 111, '39.0': 112, '4.0': 113, '40.0': 114, '41.0': 115, '42.0': 116, '43.0': 117, '44.0': 118, '45.0': 119, '46.0': 120, '47.0': 121, '48.0': 122, '49.0': 123, '5.0': 124, '50.0': 125, '51.0': 126, '52.0': 127, '53.0': 128, '54.0': 129, '55.0': 130, '56.0': 131, '57.0': 132, '58.0': 133, '59.0': 134, '6.0': 135, '60.0': 136, '61.0': 137, '62.0': 138, '63.0': 139, '64.0': 140, '65.0': 141, '66.0': 142, '67.0': 143, '68.0': 144, '69.0': 145, '7.0': 146, '70.0': 147, '71.0': 148, '72.0': 149, '73.0': 150, '74.0': 151, '75.0': 152, '76.0': 153, '77.0': 154, '78.0': 155, '79.0': 156, '8.0': 157, '81.0': 158, '83.0': 159, '84.0': 160, '85.0': 161, '86.0': 162, '87.0': 163, '88.0': 164, '89.0': 165, '9.0': 166, '90.0': 167, '91.0': 168, '93.0': 169, '94.0': 170, '95.0': 171, '97.0': 172, '99.0': 173, nan: 174}), ('seriousness', 3, {'EOS': 1, 'Value 1': 2}), ('customer', 361, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 100': 4, 'Value 101': 5, 'Value 102': 6, 'Value 103': 7, 'Value 104': 8, 'Value 105': 9, 'Value 106': 10, 'Value 107': 11, 'Value 108': 12, 'Value 11': 13, 'Value 110': 14, 'Value 111': 15, 'Value 112': 16, 'Value 113': 17, 'Value 114': 18, 'Value 115': 19, 'Value 116': 20, 'Value 117': 21, 'Value 118': 22, 'Value 119': 23, 'Value 12': 24, 'Value 120': 25, 'Value 121': 26, 'Value 122': 27, 'Value 123': 28, 'Value 124': 29, 'Value 125': 30, 'Value 126': 31, 'Value 127': 32, 'Value 129': 33, 'Value 13': 34, 'Value 131': 35, 'Value 132': 36, 'Value 133': 37, 'Value 134': 38, 'Value 135': 39, 'Value 136': 40, 'Value 137': 41, 'Value 138': 42, 'Value 139': 43, 'Value 14': 44, 'Value 140': 45, 'Value 142': 46, 'Value 143': 47, 'Value 144': 48, 'Value 145': 49, 'Value 146': 50, 'Value 147': 51, 'Value 148': 52, 'Value 149': 53, 'Value 15': 54, 'Value 150': 55, 'Value 151': 56, 'Value 152': 57, 'Value 153': 58, 'Value 154': 59, 'Value 155': 60, 'Value 156': 61, 'Value 157': 62, 'Value 158': 63, 'Value 16': 64, 'Value 160': 65, 'Value 161': 66, 'Value 162': 67, 'Value 163': 68, 'Value 164': 69, 'Value 165': 70, 'Value 166': 71, 'Value 167': 72, 'Value 168': 73, 'Value 169': 74, 'Value 17': 75, 'Value 171': 76, 'Value 172': 77, 'Value 173': 78, 'Value 174': 79, 'Value 175': 80, 'Value 176': 81, 'Value 177': 82, 'Value 178': 83, 'Value 179': 84, 'Value 18': 85, 'Value 180': 86, 'Value 181': 87, 'Value 182': 88, 'Value 183': 89, 'Value 184': 90, 'Value 185': 91, 'Value 186': 92, 'Value 187': 93, 'Value 188': 94, 'Value 189': 95, 'Value 19': 96, 'Value 190': 97, 'Value 191': 98, 'Value 192': 99, 'Value 193': 100, 'Value 194': 101, 'Value 195': 102, 'Value 196': 103, 'Value 197': 104, 'Value 198': 105, 'Value 199': 106, 'Value 2': 107, 'Value 20': 108, 'Value 200': 109, 'Value 201': 110, 'Value 202': 111, 'Value 203': 112, 'Value 204': 113, 'Value 205': 114, 'Value 206': 115, 'Value 207': 116, 'Value 208': 117, 'Value 209': 118, 'Value 21': 119, 'Value 210': 120, 'Value 211': 121, 'Value 213': 122, 'Value 214': 123, 'Value 215': 124, 'Value 216': 125, 'Value 217': 126, 'Value 218': 127, 'Value 219': 128, 'Value 22': 129, 'Value 220': 130, 'Value 221': 131, 'Value 222': 132, 'Value 223': 133, 'Value 224': 134, 'Value 225': 135, 'Value 226': 136, 'Value 227': 137, 'Value 228': 138, 'Value 229': 139, 'Value 23': 140, 'Value 230': 141, 'Value 231': 142, 'Value 232': 143, 'Value 233': 144, 'Value 234': 145, 'Value 235': 146, 'Value 236': 147, 'Value 237': 148, 'Value 238': 149, 'Value 239': 150, 'Value 24': 151, 'Value 240': 152, 'Value 241': 153, 'Value 242': 154, 'Value 243': 155, 'Value 244': 156, 'Value 245': 157, 'Value 246': 158, 'Value 247': 159, 'Value 248': 160, 'Value 249': 161, 'Value 25': 162, 'Value 250': 163, 'Value 251': 164, 'Value 252': 165, 'Value 253': 166, 'Value 254': 167, 'Value 255': 168, 'Value 256': 169, 'Value 258': 170, 'Value 259': 171, 'Value 26': 172, 'Value 260': 173, 'Value 261': 174, 'Value 262': 175, 'Value 263': 176, 'Value 264': 177, 'Value 265': 178, 'Value 266': 179, 'Value 267': 180, 'Value 269': 181, 'Value 27': 182, 'Value 271': 183, 'Value 272': 184, 'Value 273': 185, 'Value 274': 186, 'Value 275': 187, 'Value 276': 188, 'Value 277': 189, 'Value 278': 190, 'Value 279': 191, 'Value 28': 192, 'Value 280': 193, 'Value 281': 194, 'Value 282': 195, 'Value 283': 196, 'Value 284': 197, 'Value 285': 198, 'Value 286': 199, 'Value 287': 200, 'Value 288': 201, 'Value 289': 202, 'Value 29': 203, 'Value 292': 204, 'Value 293': 205, 'Value 294': 206, 'Value 296': 207, 'Value 297': 208, 'Value 298': 209, 'Value 299': 210, 'Value 3': 211, 'Value 30': 212, 'Value 300': 213, 'Value 301': 214, 'Value 302': 215, 'Value 303': 216, 'Value 304': 217, 'Value 305': 218, 'Value 306': 219, 'Value 307': 220, 'Value 308': 221, 'Value 309': 222, 'Value 31': 223, 'Value 310': 224, 'Value 311': 225, 'Value 312': 226, 'Value 313': 227, 'Value 314': 228, 'Value 315': 229, 'Value 316': 230, 'Value 317': 231, 'Value 318': 232, 'Value 319': 233, 'Value 32': 234, 'Value 320': 235, 'Value 321': 236, 'Value 322': 237, 'Value 323': 238, 'Value 324': 239, 'Value 325': 240, 'Value 326': 241, 'Value 327': 242, 'Value 328': 243, 'Value 329': 244, 'Value 33': 245, 'Value 331': 246, 'Value 332': 247, 'Value 333': 248, 'Value 334': 249, 'Value 335': 250, 'Value 336': 251, 'Value 337': 252, 'Value 338': 253, 'Value 339': 254, 'Value 34': 255, 'Value 340': 256, 'Value 342': 257, 'Value 343': 258, 'Value 344': 259, 'Value 345': 260, 'Value 346': 261, 'Value 348': 262, 'Value 349': 263, 'Value 35': 264, 'Value 350': 265, 'Value 351': 266, 'Value 352': 267, 'Value 353': 268, 'Value 356': 269, 'Value 357': 270, 'Value 36': 271, 'Value 362': 272, 'Value 363': 273, 'Value 364': 274, 'Value 365': 275, 'Value 366': 276, 'Value 368': 277, 'Value 369': 278, 'Value 37': 279, 'Value 370': 280, 'Value 374': 281, 'Value 375': 282, 'Value 376': 283, 'Value 377': 284, 'Value 379': 285, 'Value 38': 286, 'Value 380': 287, 'Value 383': 288, 'Value 384': 289, 'Value 386': 290, 'Value 388': 291, 'Value 389': 292, 'Value 39': 293, 'Value 390': 294, 'Value 393': 295, 'Value 396': 296, 'Value 4': 297, 'Value 40': 298, 'Value 41': 299, 'Value 42': 300, 'Value 43': 301, 'Value 44': 302, 'Value 45': 303, 'Value 46': 304, 'Value 47': 305, 'Value 48': 306, 'Value 49': 307, 'Value 5': 308, 'Value 50': 309, 'Value 51': 310, 'Value 52': 311, 'Value 53': 312, 'Value 54': 313, 'Value 55': 314, 'Value 56': 315, 'Value 57': 316, 'Value 58': 317, 'Value 59': 318, 'Value 6': 319, 'Value 60': 320, 'Value 61': 321, 'Value 62': 322, 'Value 63': 323, 'Value 64': 324, 'Value 65': 325, 'Value 66': 326, 'Value 67': 327, 'Value 68': 328, 'Value 69': 329, 'Value 7': 330, 'Value 70': 331, 'Value 71': 332, 'Value 72': 333, 'Value 73': 334, 'Value 74': 335, 'Value 75': 336, 'Value 76': 337, 'Value 77': 338, 'Value 78': 339, 'Value 79': 340, 'Value 8': 341, 'Value 80': 342, 'Value 81': 343, 'Value 82': 344, 'Value 83': 345, 'Value 85': 346, 'Value 86': 347, 'Value 87': 348, 'Value 88': 349, 'Value 89': 350, 'Value 9': 351, 'Value 90': 352, 'Value 91': 353, 'Value 92': 354, 'Value 93': 355, 'Value 94': 356, 'Value 96': 357, 'Value 97': 358, 'Value 98': 359, 'Value 99': 360}), ('product', 23, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 3': 16, 'Value 4': 17, 'Value 5': 18, 'Value 6': 19, 'Value 7': 20, 'Value 8': 21, 'Value 9': 22}), ('responsible_section', 9, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7, 'Value 7': 8}), ('seriousness_2', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_level', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_type', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('support_section', 8, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7}), ('workgroup', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5})], [('case_elapsed_time', 1, {}), ('event_elapsed_time', 1, {}), ('day_in_week', 1, {}), ('seconds_in_day', 1, {})])\n",
      "Encoder input features:  [['Activity', 'Resource', 'VariantIndex', 'seriousness', 'customer', 'product', 'responsible_section', 'seriousness_2', 'service_level', 'service_type', 'support_section', 'workgroup'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day']]\n",
      "Decoder input+output features:  [['Activity', 'Resource'], ['case_elapsed_time', 'event_elapsed_time']]\n",
      "\n",
      "\n",
      "Sequence length of decoder output:  4\n",
      "\n",
      "\n",
      "Cells hidden size:  128\n",
      "Number of LSTM layer:  4\n",
      "Dropout rate:  0.1\n",
      "\n",
      "\n",
      "Encoder number of labels for each input feature (categorical, numerical):  [[16, 24, 175, 3, 361, 23, 9, 6, 6, 6, 8, 6], [1, 1, 1, 1]]\n",
      "Encoder indices of tensors in dataset used as input:  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1, 2, 3]]\n",
      "Embeddings encoder:  ModuleList(\n",
      "  (0): Embedding(16, 8)\n",
      "  (1): Embedding(24, 9)\n",
      "  (2): Embedding(175, 29)\n",
      "  (3): Embedding(3, 3)\n",
      "  (4): Embedding(361, 43)\n",
      "  (5): Embedding(23, 9)\n",
      "  (6): Embedding(9, 5)\n",
      "  (7-9): 3 x Embedding(6, 4)\n",
      "  (10): Embedding(8, 5)\n",
      "  (11): Embedding(6, 4)\n",
      ")\n",
      "Total embedding feature size encoder:  127\n",
      "Total numerical feature size encoder:  4\n",
      "Input feature size encoder:  131\n",
      "Encoder initialized! \n",
      "\n",
      "Decoder label values size for each categorical input feature:  [16, 24]\n",
      "Decoder label values size for each numerical input feature:  [1, 1]\n",
      "Decoder indices of tensors in dataset used as input:  [[0, 1], [0, 1]]\n",
      "Embeddings decoder:  ModuleList(\n",
      "  (0): Embedding(16, 8)\n",
      "  (1): Embedding(24, 9)\n",
      ")\n",
      "Total embedding feature size decoder:  17\n",
      "Total numerical feature size decoder:  2\n",
      "Input feature size decoder:  19\n",
      "Output feature list of dicts (featue name, feature output size) of decoder:  [{'Activity': 16, 'Resource': 24}, {'case_elapsed_time': 1, 'event_elapsed_time': 1}]\n",
      "Decoder initialized! \n",
      "\n",
      "Output feature list of dicts (featue name, tensor index in dataset) of decoder:  [{'Activity': 0, 'Resource': 1}, {'case_elapsed_time': 0, 'event_elapsed_time': 1}]\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "\n",
    "\n",
    "file_path_model = '../../notebooks/training_variational_dropout/Helpdesk/Helpdesk_full_grad_norm_new_4layer.pkl'\n",
    "model = DropoutUncertaintyEncoderDecoderLSTM.load(file_path_model, dropout=0.1)\n",
    "\n",
    "# Load the dataset\n",
    "file_path_data_set = '../../../encoded_data/test_weytjens//helpdesk_all_5_test.pkl'\n",
    "helpdesk_test_dataset = torch.load(file_path_data_set, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aac0532e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import evaluation.probabilistic_evaluation\n",
    "importlib.reload(evaluation.probabilistic_evaluation)\n",
    "from evaluation.probabilistic_evaluation import ProbabilisticEvaluation\n",
    "\n",
    "new_eval = ProbabilisticEvaluation(model=model, \n",
    "                                   dataset=helpdesk_test_dataset,\n",
    "                                   concept_name='Activity',\n",
    "                                   num_processes=16,\n",
    "                                   #growing_num_values = [],\n",
    "                                   growing_num_values = ['case_elapsed_time'],\n",
    "                                   samples_per_case = 100,\n",
    "                                   sample_argmax = False,\n",
    "                                   use_variance_cat = True,\n",
    "                                   use_variance_num = True,\n",
    "                                   all_cat=['Activity', 'Resource'],\n",
    "                                   all_num=['case_elapsed_time', 'event_elapsed_time'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b320a59f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a833966c6b40452a88419416ad03f207",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/916 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 12\u001b[39m\n\u001b[32m      9\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m j, (prefix_len, prefix, suffix) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(new_eval._iterate_case(full_case)):\n\u001b[32m     10\u001b[39m     model.eval()\n\u001b[32m---> \u001b[39m\u001b[32m12\u001b[39m     predictions, (h, c), seq_len_pred, output_feature_indeces, prefixes = \u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreturns_prefix\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     13\u001b[39m     \u001b[38;5;28mprint\u001b[39m(predictions[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mActivity_mean\u001b[39m\u001b[33m\"\u001b[39m])\n\u001b[32m     14\u001b[39m     target = predictions[\u001b[32m0\u001b[39m][\u001b[32m0\u001b[39m][\u001b[33m\"\u001b[39m\u001b[33mActivity_mean\u001b[39m\u001b[33m\"\u001b[39m][t, b]\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/XAI-Probabilistic_Suffix_Prediction_U-ED-LSTM_pub/src/aa_philipp/notebooks/../../model/dropout_uncertainty_enc_dec_LSTM/dropout_uncertainty_model.py:319\u001b[39m, in \u001b[36mDropoutUncertaintyEncoderDecoderLSTM.forward\u001b[39m\u001b[34m(self, prefixes, suffixes, teacher_forcing_ratio, returns_prefix)\u001b[39m\n\u001b[32m    316\u001b[39m (h_enc, c_enc), prefixes = \u001b[38;5;28mself\u001b[39m.encoder(\u001b[38;5;28minput\u001b[39m=prefixes, returns_prefix=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    318\u001b[39m \u001b[38;5;66;03m# Get SOS event: Last prefx event:\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m319\u001b[39m cat_prefixes, num_prefixes = prefixes\n\u001b[32m    320\u001b[39m cat_sos_events = [cat_tens[:, -\u001b[32m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m cat_tens \u001b[38;5;129;01min\u001b[39;00m cat_prefixes]\n\u001b[32m    321\u001b[39m num_sos_events = [num_tens[:, -\u001b[32m1\u001b[39m:] \u001b[38;5;28;01mfor\u001b[39;00m num_tens \u001b[38;5;129;01min\u001b[39;00m num_prefixes]\n",
      "\u001b[31mValueError\u001b[39m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "\n",
    "t = 0\n",
    "b = 0\n",
    "class_id = 1\n",
    "\n",
    "case_items = list(new_eval.cases.items())\n",
    "for i, (case_name, full_case) in tqdm(enumerate(case_items), total=len(new_eval.cases)):\n",
    "    for j, (prefix_len, prefix, suffix) in enumerate(new_eval._iterate_case(full_case)):\n",
    "        model.eval()\n",
    "\n",
    "        predictions, (h, c), seq_len_pred, output_feature_indeces, prefixes = model.forward(prefix, returns_prefix=True)\n",
    "\n",
    "        target = predictions[0][0][\"Activity_mean\"][t, b]\n",
    "        \n",
    "        model.zero_grad(set_to_none=True)\n",
    "        target.backward()\n",
    "        saliency = prefixes.grad.abs()\n",
    "        \n",
    "        print(saliency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60886245",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counts: 2295 1028\n",
      "Correlation r = 0.169720, p = 6.756917e-23\n",
      "Welch t-test: t = 10.337822, p = 1.727732e-24\n",
      "Mann–Whitney U: U = 1564346.000000, p = 3.497120e-51\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import ttest_ind, mannwhitneyu, pearsonr\n",
    "\n",
    "df = results_df.copy()\n",
    "\n",
    "# 1) Ensure correctness is boolean/int\n",
    "df[\"next_activity_correctness\"] = df[\"next_activity_correctness\"].astype(bool)\n",
    "df[\"correctness_int\"] = df[\"next_activity_correctness\"].astype(int)\n",
    "\n",
    "# 2) Coerce timeaccuracy to numeric (turns non-numeric strings into NaN)\n",
    "df[\"next_activity_timeaccuracy\"] = pd.to_numeric(df[\"next_activity_timeaccuracy\"], errors=\"coerce\")\n",
    "\n",
    "# 3) Remove NaN/inf values\n",
    "df = df.replace([np.inf, -np.inf], np.nan)\n",
    "df = df.dropna(subset=[\"next_activity_timeaccuracy\", \"correctness_int\"])\n",
    "\n",
    "# Masks after cleaning\n",
    "correct_mask = df[\"next_activity_correctness\"]\n",
    "incorrect_mask = ~df[\"next_activity_correctness\"]\n",
    "\n",
    "correct_values = df.loc[correct_mask, \"next_activity_timeaccuracy\"].astype(float).to_numpy()\n",
    "incorrect_values = df.loc[incorrect_mask, \"next_activity_timeaccuracy\"].astype(float).to_numpy()\n",
    "\n",
    "print(\"Counts:\", correct_values.size, incorrect_values.size)\n",
    "\n",
    "# ---- A) P-value for correlation (point-biserial == Pearson with 0/1)\n",
    "r, p_corr = pearsonr(df[\"next_activity_timeaccuracy\"].to_numpy(),\n",
    "                     df[\"correctness_int\"].to_numpy())\n",
    "print(f\"Correlation r = {r:.6f}, p = {p_corr:.6e}\")\n",
    "\n",
    "# ---- B) P-value for difference in means (Welch t-test)\n",
    "t_stat, p_t = ttest_ind(correct_values, incorrect_values, equal_var=False)\n",
    "print(f\"Welch t-test: t = {t_stat:.6f}, p = {p_t:.6e}\")\n",
    "\n",
    "# ---- C) Non-parametric alternative (often better for skewed time deltas)\n",
    "u_stat, p_u = mannwhitneyu(correct_values, incorrect_values, alternative=\"two-sided\")\n",
    "print(f\"Mann–Whitney U: U = {u_stat:.6f}, p = {p_u:.6e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8b2d217",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5161"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from event_log_loader.new_event_log_loader import EventLogDataset\n",
    "\n",
    " # eval mode for inference\n",
    "\n",
    "\n",
    "helpdesk_test_dataset: EventLogDataset = helpdesk_test_dataset\n",
    "\n",
    "cat_tensors, num_tensors, case_ids = helpdesk_test_dataset.tensor_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2dd805d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.0997e+00,\n",
       "           3.8361e+00, -2.0086e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.8361e+00,\n",
       "          -2.0086e-08, -2.0086e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.0086e-08,\n",
       "          -2.0086e-08, -2.0086e-08],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.0086e-08,\n",
       "          -2.0086e-08, -2.0086e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.0086e-08,\n",
       "          -2.0086e-08, -2.0086e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.0086e-08,\n",
       "          -2.0086e-08, -2.0086e-08]]),\n",
       " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.2131e+00,\n",
       "           5.3174e+00,  3.0736e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  5.3174e+00,\n",
       "           3.0736e-08,  3.0736e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.0736e-08,\n",
       "           3.0736e-08,  3.0736e-08],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.0736e-08,\n",
       "           3.0736e-08,  3.0736e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.0736e-08,\n",
       "           3.0736e-08,  3.0736e-08],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  3.0736e-08,\n",
       "           3.0736e-08,  3.0736e-08]]),\n",
       " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -2.7577e-01,\n",
       "           2.4835e+00,  6.3343e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  2.4835e+00,\n",
       "           6.3343e-09,  6.3343e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.3343e-09,\n",
       "           6.3343e-09,  6.3343e-09],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.3343e-09,\n",
       "           6.3343e-09,  6.3343e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.3343e-09,\n",
       "           6.3343e-09,  6.3343e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  6.3343e-09,\n",
       "           6.3343e-09,  6.3343e-09]]),\n",
       " tensor([[ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ...,  1.5310e+00,\n",
       "          -1.9797e+00, -1.3392e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.9797e+00,\n",
       "          -1.3392e-09, -1.3392e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.3392e-09,\n",
       "          -1.3392e-09, -1.3392e-09],\n",
       "         ...,\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.3392e-09,\n",
       "          -1.3392e-09, -1.3392e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.3392e-09,\n",
       "          -1.3392e-09, -1.3392e-09],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  ..., -1.3392e-09,\n",
       "          -1.3392e-09, -1.3392e-09]]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4c051424",
   "metadata": {},
   "source": [
    "# Thema: Saliency Maps:\n",
    "\n",
    "\n",
    "### Grundansatz:\n",
    "1. Eine simpele (vanilla) gradient based saliency map entweder einem timestep und entweder bzgl. einer activity oder der temporal component\n",
    "2. Erweiterung auf Integrated Gradient (soll besser sein, da es sich auf einen baseline input bezieht)\n",
    "3. Dann SHAP und, wenn zu komplex/compute intense für das model, deepSHAP\n",
    "\n",
    "### Problem: (Ich 1. hab probiert)\n",
    "\n",
    "- Starke anpassungen im model notwendig -> sehr zeitaufwändig (evtl. kann ich es in simpleren model probieren?)\n",
    "- Zentrales Problem: \"Preprocessing\" passiert noch in der inference() und forward() methode"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI-Probabilistic_Suffix_Prediction_U-ED-L-p9C7deWr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
