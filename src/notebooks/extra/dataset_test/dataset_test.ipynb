{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "04de577c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import torch\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../..')\n",
    "sys.path.insert(0, '../../..')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "03b99ded",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "helpdesk_all_lognormal_1_test.pkl   helpdesk_all_lognormal_5_test.pkl\n",
      "helpdesk_all_lognormal_1_train.pkl  helpdesk_all_lognormal_5_train.pkl\n",
      "helpdesk_all_lognormal_1_val.pkl    helpdesk_all_lognormal_5_val.pkl\n"
     ]
    }
   ],
   "source": [
    "!ls ../../../../../risk_controlled_proactive_conformance_checking_dev/data/encoded_data/Helpdesk/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "01d5cd14",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Path to your pickle file (saved with torch.save)\n",
    "file_path_train = '../../../../../risk_controlled_proactive_conformance_checking_dev/data/encoded_data/Helpdesk/helpdesk_all_lognormal_5_train.pkl'\n",
    "helpdesk_train_5_dataset = torch.load(file_path_train, weights_only=False)\n",
    "\n",
    "# Path to your pickle file (saved with torch.save)\n",
    "file_path_val = '../../../../../risk_controlled_proactive_conformance_checking_dev/data/encoded_data/Helpdesk/helpdesk_all_lognormal_1_train.pkl'\n",
    "helpdesk_train_1_dataset = torch.load(file_path_val, weights_only=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "abf4ec2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Len train_5: 15612\n",
      "Len train_1: 15612\n",
      "((tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  1, 13, 11,  2,  5]), tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 13, 13, 13, 19,  1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1]), tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0, 16, 16, 16, 16,  1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2, 2, 2, 2, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3, 3, 3, 3, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 4, 4, 1])), (tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -2.7024e-01,  1.5691e+00,\n",
      "         1.5691e+00,  2.4888e+00, -6.3299e-09]), tensor([ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
      "         0.0000e+00,  0.0000e+00,  0.0000e+00, -1.4823e+00, -1.5089e+00,\n",
      "        -1.5080e+00, -1.9975e+00,  2.8312e-08]), tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000, -2.5328,  0.6721,  0.6721,\n",
      "         0.7447,  0.4544]), tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.3793,  0.7716, -3.4421,\n",
      "         0.4758,  0.3793])), 'Case 10')\n",
      "((tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]), tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0, 13]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 1]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 3]), tensor([ 0,  0,  0,  0,  0,  0,  0,  0,  0, 16]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 3]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 4]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 2]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 3]), tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 4])), (tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -0.2070]), tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -1.1355]), tensor([ 0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,  0.0000,\n",
      "         0.0000, -1.8337]), tensor([0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000, 0.0000,\n",
      "        0.5224])), 'Case 10')\n"
     ]
    }
   ],
   "source": [
    "print(\"Len train_5:\", len(helpdesk_train_5_dataset))\n",
    "print(\"Len train_1:\", len(helpdesk_train_1_dataset))\n",
    "\n",
    "print(helpdesk_train_5_dataset[0])\n",
    "print(helpdesk_train_1_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "40390e27",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "too many indices for tensor of dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[14], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m case_ids_5 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(\u001b[43mhelpdesk_train_5_dataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcase_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m)\n\u001b[1;32m      2\u001b[0m case_ids_1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(helpdesk_train_1_dataset[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcase_ids\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSame length:\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28mlen\u001b[39m(case_ids_5) \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(case_ids_1))\n",
      "File \u001b[0;32m~/ProbabilisticSuffixPredictionLab/probabilistic_suffix_prediction_dev/src/notebooks/extra/dataset_test/../../../event_log_loader/new_event_log_loader.py:511\u001b[0m, in \u001b[0;36mEventLogDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m    509\u001b[0m \u001b[38;5;66;03m#categorical items\u001b[39;00m\n\u001b[1;32m    510\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtensor_list[\u001b[38;5;241m0\u001b[39m]:\n\u001b[0;32m--> 511\u001b[0m     cat\u001b[38;5;241m.\u001b[39mappend(\u001b[43mi\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m)\n\u001b[1;32m    512\u001b[0m \u001b[38;5;66;03m#continuous items\u001b[39;00m\n\u001b[1;32m    513\u001b[0m cont \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m()\n",
      "\u001b[0;31mIndexError\u001b[0m: too many indices for tensor of dimension 2"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "probabilistic_suffix_prediction_dev-Otdb6r1k",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
