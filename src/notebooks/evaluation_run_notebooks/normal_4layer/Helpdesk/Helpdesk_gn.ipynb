{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "import sys\n",
    "import torch\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../..')\n",
    "sys.path.insert(0, '../../..')\n",
    "sys.path.insert(0, '../../../..')\n",
    "\n",
    "from model.dropout_uncertainty_enc_dec_LSTM.dropout_uncertainty_model import DropoutUncertaintyEncoderDecoderLSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set categories:  ([('Activity', 16, {'Assign seriousness': 1, 'Closed': 2, 'Create SW anomaly': 3, 'DUPLICATE': 4, 'EOS': 5, 'INVALID': 6, 'Insert ticket': 7, 'RESOLVED': 8, 'Require upgrade': 9, 'Resolve SW anomaly': 10, 'Resolve ticket': 11, 'Schedule intervention': 12, 'Take in charge ticket': 13, 'VERIFIED': 14, 'Wait': 15}), ('Resource', 24, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 22': 16, 'Value 3': 17, 'Value 4': 18, 'Value 5': 19, 'Value 6': 20, 'Value 7': 21, 'Value 8': 22, 'Value 9': 23}), ('VariantIndex', 175, {'1.0': 1, '10.0': 2, '100.0': 3, '103.0': 4, '104.0': 5, '107.0': 6, '109.0': 7, '11.0': 8, '110.0': 9, '112.0': 10, '113.0': 11, '114.0': 12, '115.0': 13, '117.0': 14, '118.0': 15, '12.0': 16, '120.0': 17, '122.0': 18, '123.0': 19, '124.0': 20, '125.0': 21, '126.0': 22, '127.0': 23, '129.0': 24, '13.0': 25, '130.0': 26, '131.0': 27, '134.0': 28, '135.0': 29, '137.0': 30, '138.0': 31, '139.0': 32, '14.0': 33, '140.0': 34, '141.0': 35, '143.0': 36, '145.0': 37, '147.0': 38, '149.0': 39, '15.0': 40, '150.0': 41, '151.0': 42, '152.0': 43, '153.0': 44, '154.0': 45, '155.0': 46, '156.0': 47, '157.0': 48, '158.0': 49, '16.0': 50, '162.0': 51, '163.0': 52, '164.0': 53, '165.0': 54, '167.0': 55, '168.0': 56, '169.0': 57, '17.0': 58, '170.0': 59, '172.0': 60, '173.0': 61, '175.0': 62, '176.0': 63, '179.0': 64, '18.0': 65, '180.0': 66, '181.0': 67, '182.0': 68, '183.0': 69, '188.0': 70, '19.0': 71, '192.0': 72, '193.0': 73, '194.0': 74, '195.0': 75, '197.0': 76, '199.0': 77, '2.0': 78, '20.0': 79, '202.0': 80, '203.0': 81, '204.0': 82, '205.0': 83, '207.0': 84, '208.0': 85, '21.0': 86, '211.0': 87, '212.0': 88, '214.0': 89, '217.0': 90, '22.0': 91, '220.0': 92, '222.0': 93, '225.0': 94, '23.0': 95, '24.0': 96, '25.0': 97, '26.0': 98, '27.0': 99, '28.0': 100, '29.0': 101, '3.0': 102, '30.0': 103, '31.0': 104, '32.0': 105, '33.0': 106, '34.0': 107, '35.0': 108, '36.0': 109, '37.0': 110, '38.0': 111, '39.0': 112, '4.0': 113, '40.0': 114, '41.0': 115, '42.0': 116, '43.0': 117, '44.0': 118, '45.0': 119, '46.0': 120, '47.0': 121, '48.0': 122, '49.0': 123, '5.0': 124, '50.0': 125, '51.0': 126, '52.0': 127, '53.0': 128, '54.0': 129, '55.0': 130, '56.0': 131, '57.0': 132, '58.0': 133, '59.0': 134, '6.0': 135, '60.0': 136, '61.0': 137, '62.0': 138, '63.0': 139, '64.0': 140, '65.0': 141, '66.0': 142, '67.0': 143, '68.0': 144, '69.0': 145, '7.0': 146, '70.0': 147, '71.0': 148, '72.0': 149, '73.0': 150, '74.0': 151, '75.0': 152, '76.0': 153, '77.0': 154, '78.0': 155, '79.0': 156, '8.0': 157, '81.0': 158, '83.0': 159, '84.0': 160, '85.0': 161, '86.0': 162, '87.0': 163, '88.0': 164, '89.0': 165, '9.0': 166, '90.0': 167, '91.0': 168, '93.0': 169, '94.0': 170, '95.0': 171, '97.0': 172, '99.0': 173, nan: 174}), ('seriousness', 3, {'EOS': 1, 'Value 1': 2}), ('customer', 361, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 100': 4, 'Value 101': 5, 'Value 102': 6, 'Value 103': 7, 'Value 104': 8, 'Value 105': 9, 'Value 106': 10, 'Value 107': 11, 'Value 108': 12, 'Value 11': 13, 'Value 110': 14, 'Value 111': 15, 'Value 112': 16, 'Value 113': 17, 'Value 114': 18, 'Value 115': 19, 'Value 116': 20, 'Value 117': 21, 'Value 118': 22, 'Value 119': 23, 'Value 12': 24, 'Value 120': 25, 'Value 121': 26, 'Value 122': 27, 'Value 123': 28, 'Value 124': 29, 'Value 125': 30, 'Value 126': 31, 'Value 127': 32, 'Value 129': 33, 'Value 13': 34, 'Value 131': 35, 'Value 132': 36, 'Value 133': 37, 'Value 134': 38, 'Value 135': 39, 'Value 136': 40, 'Value 137': 41, 'Value 138': 42, 'Value 139': 43, 'Value 14': 44, 'Value 140': 45, 'Value 142': 46, 'Value 143': 47, 'Value 144': 48, 'Value 145': 49, 'Value 146': 50, 'Value 147': 51, 'Value 148': 52, 'Value 149': 53, 'Value 15': 54, 'Value 150': 55, 'Value 151': 56, 'Value 152': 57, 'Value 153': 58, 'Value 154': 59, 'Value 155': 60, 'Value 156': 61, 'Value 157': 62, 'Value 158': 63, 'Value 16': 64, 'Value 160': 65, 'Value 161': 66, 'Value 162': 67, 'Value 163': 68, 'Value 164': 69, 'Value 165': 70, 'Value 166': 71, 'Value 167': 72, 'Value 168': 73, 'Value 169': 74, 'Value 17': 75, 'Value 171': 76, 'Value 172': 77, 'Value 173': 78, 'Value 174': 79, 'Value 175': 80, 'Value 176': 81, 'Value 177': 82, 'Value 178': 83, 'Value 179': 84, 'Value 18': 85, 'Value 180': 86, 'Value 181': 87, 'Value 182': 88, 'Value 183': 89, 'Value 184': 90, 'Value 185': 91, 'Value 186': 92, 'Value 187': 93, 'Value 188': 94, 'Value 189': 95, 'Value 19': 96, 'Value 190': 97, 'Value 191': 98, 'Value 192': 99, 'Value 193': 100, 'Value 194': 101, 'Value 195': 102, 'Value 196': 103, 'Value 197': 104, 'Value 198': 105, 'Value 199': 106, 'Value 2': 107, 'Value 20': 108, 'Value 200': 109, 'Value 201': 110, 'Value 202': 111, 'Value 203': 112, 'Value 204': 113, 'Value 205': 114, 'Value 206': 115, 'Value 207': 116, 'Value 208': 117, 'Value 209': 118, 'Value 21': 119, 'Value 210': 120, 'Value 211': 121, 'Value 213': 122, 'Value 214': 123, 'Value 215': 124, 'Value 216': 125, 'Value 217': 126, 'Value 218': 127, 'Value 219': 128, 'Value 22': 129, 'Value 220': 130, 'Value 221': 131, 'Value 222': 132, 'Value 223': 133, 'Value 224': 134, 'Value 225': 135, 'Value 226': 136, 'Value 227': 137, 'Value 228': 138, 'Value 229': 139, 'Value 23': 140, 'Value 230': 141, 'Value 231': 142, 'Value 232': 143, 'Value 233': 144, 'Value 234': 145, 'Value 235': 146, 'Value 236': 147, 'Value 237': 148, 'Value 238': 149, 'Value 239': 150, 'Value 24': 151, 'Value 240': 152, 'Value 241': 153, 'Value 242': 154, 'Value 243': 155, 'Value 244': 156, 'Value 245': 157, 'Value 246': 158, 'Value 247': 159, 'Value 248': 160, 'Value 249': 161, 'Value 25': 162, 'Value 250': 163, 'Value 251': 164, 'Value 252': 165, 'Value 253': 166, 'Value 254': 167, 'Value 255': 168, 'Value 256': 169, 'Value 258': 170, 'Value 259': 171, 'Value 26': 172, 'Value 260': 173, 'Value 261': 174, 'Value 262': 175, 'Value 263': 176, 'Value 264': 177, 'Value 265': 178, 'Value 266': 179, 'Value 267': 180, 'Value 269': 181, 'Value 27': 182, 'Value 271': 183, 'Value 272': 184, 'Value 273': 185, 'Value 274': 186, 'Value 275': 187, 'Value 276': 188, 'Value 277': 189, 'Value 278': 190, 'Value 279': 191, 'Value 28': 192, 'Value 280': 193, 'Value 281': 194, 'Value 282': 195, 'Value 283': 196, 'Value 284': 197, 'Value 285': 198, 'Value 286': 199, 'Value 287': 200, 'Value 288': 201, 'Value 289': 202, 'Value 29': 203, 'Value 292': 204, 'Value 293': 205, 'Value 294': 206, 'Value 296': 207, 'Value 297': 208, 'Value 298': 209, 'Value 299': 210, 'Value 3': 211, 'Value 30': 212, 'Value 300': 213, 'Value 301': 214, 'Value 302': 215, 'Value 303': 216, 'Value 304': 217, 'Value 305': 218, 'Value 306': 219, 'Value 307': 220, 'Value 308': 221, 'Value 309': 222, 'Value 31': 223, 'Value 310': 224, 'Value 311': 225, 'Value 312': 226, 'Value 313': 227, 'Value 314': 228, 'Value 315': 229, 'Value 316': 230, 'Value 317': 231, 'Value 318': 232, 'Value 319': 233, 'Value 32': 234, 'Value 320': 235, 'Value 321': 236, 'Value 322': 237, 'Value 323': 238, 'Value 324': 239, 'Value 325': 240, 'Value 326': 241, 'Value 327': 242, 'Value 328': 243, 'Value 329': 244, 'Value 33': 245, 'Value 331': 246, 'Value 332': 247, 'Value 333': 248, 'Value 334': 249, 'Value 335': 250, 'Value 336': 251, 'Value 337': 252, 'Value 338': 253, 'Value 339': 254, 'Value 34': 255, 'Value 340': 256, 'Value 342': 257, 'Value 343': 258, 'Value 344': 259, 'Value 345': 260, 'Value 346': 261, 'Value 348': 262, 'Value 349': 263, 'Value 35': 264, 'Value 350': 265, 'Value 351': 266, 'Value 352': 267, 'Value 353': 268, 'Value 356': 269, 'Value 357': 270, 'Value 36': 271, 'Value 362': 272, 'Value 363': 273, 'Value 364': 274, 'Value 365': 275, 'Value 366': 276, 'Value 368': 277, 'Value 369': 278, 'Value 37': 279, 'Value 370': 280, 'Value 374': 281, 'Value 375': 282, 'Value 376': 283, 'Value 377': 284, 'Value 379': 285, 'Value 38': 286, 'Value 380': 287, 'Value 383': 288, 'Value 384': 289, 'Value 386': 290, 'Value 388': 291, 'Value 389': 292, 'Value 39': 293, 'Value 390': 294, 'Value 393': 295, 'Value 396': 296, 'Value 4': 297, 'Value 40': 298, 'Value 41': 299, 'Value 42': 300, 'Value 43': 301, 'Value 44': 302, 'Value 45': 303, 'Value 46': 304, 'Value 47': 305, 'Value 48': 306, 'Value 49': 307, 'Value 5': 308, 'Value 50': 309, 'Value 51': 310, 'Value 52': 311, 'Value 53': 312, 'Value 54': 313, 'Value 55': 314, 'Value 56': 315, 'Value 57': 316, 'Value 58': 317, 'Value 59': 318, 'Value 6': 319, 'Value 60': 320, 'Value 61': 321, 'Value 62': 322, 'Value 63': 323, 'Value 64': 324, 'Value 65': 325, 'Value 66': 326, 'Value 67': 327, 'Value 68': 328, 'Value 69': 329, 'Value 7': 330, 'Value 70': 331, 'Value 71': 332, 'Value 72': 333, 'Value 73': 334, 'Value 74': 335, 'Value 75': 336, 'Value 76': 337, 'Value 77': 338, 'Value 78': 339, 'Value 79': 340, 'Value 8': 341, 'Value 80': 342, 'Value 81': 343, 'Value 82': 344, 'Value 83': 345, 'Value 85': 346, 'Value 86': 347, 'Value 87': 348, 'Value 88': 349, 'Value 89': 350, 'Value 9': 351, 'Value 90': 352, 'Value 91': 353, 'Value 92': 354, 'Value 93': 355, 'Value 94': 356, 'Value 96': 357, 'Value 97': 358, 'Value 98': 359, 'Value 99': 360}), ('product', 23, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 3': 16, 'Value 4': 17, 'Value 5': 18, 'Value 6': 19, 'Value 7': 20, 'Value 8': 21, 'Value 9': 22}), ('responsible_section', 9, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7, 'Value 7': 8}), ('seriousness_2', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_level', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('service_type', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5}), ('support_section', 8, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5, 'Value 5': 6, 'Value 6': 7}), ('workgroup', 6, {'EOS': 1, 'Value 1': 2, 'Value 2': 3, 'Value 3': 4, 'Value 4': 5})], [('case_elapsed_time', 1, {}), ('event_elapsed_time', 1, {}), ('day_in_week', 1, {}), ('seconds_in_day', 1, {})])\n",
      "Encoder input features:  [['Activity', 'Resource', 'VariantIndex', 'seriousness', 'customer', 'product', 'responsible_section', 'seriousness_2', 'service_level', 'service_type', 'support_section', 'workgroup'], ['case_elapsed_time', 'event_elapsed_time', 'day_in_week', 'seconds_in_day']]\n",
      "Decoder input+output features:  [['Activity', 'Resource'], ['case_elapsed_time', 'event_elapsed_time']]\n",
      "\n",
      "\n",
      "Sequence length of decoder output:  4\n",
      "\n",
      "\n",
      "Cells hidden size:  128\n",
      "Number of LSTM layer:  4\n",
      "Dropout rate:  0.1\n",
      "\n",
      "\n",
      "Encoder number of labels for each input feature (categorical, numerical):  [[16, 24, 175, 3, 361, 23, 9, 6, 6, 6, 8, 6], [1, 1, 1, 1]]\n",
      "Encoder indices of tensors in dataset used as input:  [[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11], [0, 1, 2, 3]]\n",
      "Embeddings encoder:  ModuleList(\n",
      "  (0): Embedding(16, 8)\n",
      "  (1): Embedding(24, 9)\n",
      "  (2): Embedding(175, 29)\n",
      "  (3): Embedding(3, 3)\n",
      "  (4): Embedding(361, 43)\n",
      "  (5): Embedding(23, 9)\n",
      "  (6): Embedding(9, 5)\n",
      "  (7-9): 3 x Embedding(6, 4)\n",
      "  (10): Embedding(8, 5)\n",
      "  (11): Embedding(6, 4)\n",
      ")\n",
      "Total embedding feature size encoder:  127\n",
      "Total numerical feature size encoder:  4\n",
      "Input feature size encoder:  131\n",
      "Encoder initialized! \n",
      "\n",
      "Decoder label values size for each categorical input feature:  [16, 24]\n",
      "Decoder label values size for each numerical input feature:  [1, 1]\n",
      "Decoder indices of tensors in dataset used as input:  [[0, 1], [0, 1]]\n",
      "Embeddings decoder:  ModuleList(\n",
      "  (0): Embedding(16, 8)\n",
      "  (1): Embedding(24, 9)\n",
      ")\n",
      "Total embedding feature size decoder:  17\n",
      "Total numerical feature size decoder:  2\n",
      "Input feature size decoder:  19\n",
      "Output feature list of dicts (featue name, feature output size) of decoder:  [{'Activity': 16, 'Resource': 24}, {'case_elapsed_time': 1, 'event_elapsed_time': 1}]\n",
      "Decoder initialized! \n",
      "\n",
      "Output feature list of dicts (featue name, tensor index in dataset) of decoder:  [{'Activity': 0, 'Resource': 1}, {'case_elapsed_time': 0, 'event_elapsed_time': 1}]\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "file_path_model = '../../../training_variational_dropout/Helpdesk/Helpdesk_full_grad_norm_new_4layer.pkl'\n",
    "model = DropoutUncertaintyEncoderDecoderLSTM.load(file_path_model, dropout=0.1)\n",
    "\n",
    "# Load the dataset\n",
    "file_path_data_set = '../../../../../encoded_data/test_weytjens//helpdesk_all_5_test.pkl'\n",
    "helpdesk_test_dataset = torch.load(file_path_data_set, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluation.probabilistic_evaluation\n",
    "importlib.reload(evaluation.probabilistic_evaluation)\n",
    "from evaluation.probabilistic_evaluation import ProbabilisticEvaluation\n",
    "\n",
    "new_eval = ProbabilisticEvaluation(model=model, \n",
    "                                   dataset=helpdesk_test_dataset,\n",
    "                                   concept_name='Activity',\n",
    "                                   num_processes=16,\n",
    "                                   #growing_num_values = [],\n",
    "                                   growing_num_values = ['case_elapsed_time'],\n",
    "                                   samples_per_case = 100,\n",
    "                                   sample_argmax = False,\n",
    "                                   use_variance_cat = True,\n",
    "                                   use_variance_num = True,\n",
    "                                   all_cat=['Activity', 'Resource'],\n",
    "                                   all_num=['case_elapsed_time', 'event_elapsed_time'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0eee022ef75c45d189218e17b2d60265",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/916 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 5\n",
      "2 4\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 13\u001b[39m\n\u001b[32m     10\u001b[39m save_every = \u001b[32m10\u001b[39m\n\u001b[32m     12\u001b[39m results = {}\n\u001b[32m---> \u001b[39m\u001b[32m13\u001b[39m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mcase_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_suffixes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_prediction\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnew_eval\u001b[49m\u001b[43m.\u001b[49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_order\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01massert\u001b[39;49;00m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcase_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresults\u001b[49m\u001b[43m[\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcase_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_len\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmean_prediction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_suffixes\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/XAI-Probabilistic_Suffix_Prediction_U-ED-LSTM_pub/src/notebooks/evaluation_run_notebooks/normal_4layer/Helpdesk/../../../../evaluation/probabilistic_evaluation.py:192\u001b[39m, in \u001b[36mProbabilisticEvaluation.evaluate\u001b[39m\u001b[34m(self, random_order, include_model_states)\u001b[39m\n\u001b[32m    190\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (case_name, full_case) \u001b[38;5;129;01min\u001b[39;00m tqdm(\u001b[38;5;28menumerate\u001b[39m(case_items), total=\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m.cases)):\n\u001b[32m    191\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m j, (prefix_len, prefix, suffix) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m._iterate_case(full_case)):\n\u001b[32m--> \u001b[39m\u001b[32m192\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_evaluate_single\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcase_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_model_states\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/XAI-Probabilistic_Suffix_Prediction_U-ED-LSTM_pub/src/notebooks/evaluation_run_notebooks/normal_4layer/Helpdesk/../../../../evaluation/probabilistic_evaluation.py:171\u001b[39m, in \u001b[36mProbabilisticEvaluation._evaluate_single\u001b[39m\u001b[34m(self, case_name, prefix_len, prefix, suffix, include_model_states)\u001b[39m\n\u001b[32m    168\u001b[39m mean_prediction = \u001b[38;5;28mself\u001b[39m._predict_suffix_with_means(prefix, prefix_len)\n\u001b[32m    169\u001b[39m \u001b[38;5;66;03m# print(\"Mean Pred: \", mean_prediction)\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m171\u001b[39m predicted_suffixes = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mpredict_probabilistic_suffix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_model_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    173\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m case_name, prefix_len, readable_prefix, predicted_suffixes, readable_suffix, mean_prediction\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/XAI-Probabilistic_Suffix_Prediction_U-ED-LSTM_pub/src/notebooks/evaluation_run_notebooks/normal_4layer/Helpdesk/../../../../evaluation/probabilistic_evaluation.py:155\u001b[39m, in \u001b[36mProbabilisticEvaluation.predict_probabilistic_suffix\u001b[39m\u001b[34m(self, prefix, prefix_len, include_model_states)\u001b[39m\n\u001b[32m    153\u001b[39m suffixes = []\n\u001b[32m    154\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m.samples_per_case):\n\u001b[32m--> \u001b[39m\u001b[32m155\u001b[39m     suffix = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msample_suffix\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprefix_len\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minclude_model_states\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    156\u001b[39m     suffixes.append(suffix)\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m suffixes\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/XAI-Probabilistic_Suffix_Prediction_U-ED-LSTM_pub/src/notebooks/evaluation_run_notebooks/normal_4layer/Helpdesk/../../../../evaluation/probabilistic_evaluation.py:112\u001b[39m, in \u001b[36mProbabilisticEvaluation.sample_suffix\u001b[39m\u001b[34m(self, prefix, prefix_len, include_model_states)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34msample_suffix\u001b[39m(\u001b[38;5;28mself\u001b[39m, prefix, prefix_len, include_model_states):\n\u001b[32m--> \u001b[39m\u001b[32m112\u001b[39m     prediction, (h, c), z = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43minference\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    113\u001b[39m     suffix = []\n\u001b[32m    114\u001b[39m     max_iteration = \u001b[38;5;28mself\u001b[39m.dataset.encoder_decoder.window_size - \\\n\u001b[32m    115\u001b[39m                     \u001b[38;5;28mself\u001b[39m.dataset.encoder_decoder.min_suffix_size - \\\n\u001b[32m    116\u001b[39m                     prefix_len\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/XAI-Probabilistic_Suffix_Prediction_U-ED-LSTM_pub/src/notebooks/evaluation_run_notebooks/normal_4layer/Helpdesk/../../../../model/dropout_uncertainty_enc_dec_LSTM/dropout_uncertainty_model.py:405\u001b[39m, in \u001b[36mDropoutUncertaintyEncoderDecoderLSTM.inference\u001b[39m\u001b[34m(self, prefix, last_event, hx, z)\u001b[39m\n\u001b[32m    401\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m    402\u001b[39m     \u001b[38;5;66;03m# First Prediciton\u001b[39;00m\n\u001b[32m    403\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m prefix \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    404\u001b[39m         \u001b[38;5;66;03m# Call encoder\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m405\u001b[39m         (h_enc, c_enc) = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43mprefix\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    407\u001b[39m         \u001b[38;5;66;03m# Get SOS event: Last prefx event:\u001b[39;00m\n\u001b[32m    408\u001b[39m         cat_prefixes, num_prefixes = prefix\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/XAI-Probabilistic_Suffix_Prediction_U-ED-L-p9C7deWr/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/XAI-Probabilistic_Suffix_Prediction_U-ED-L-p9C7deWr/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/XAI-Probabilistic_Suffix_Prediction_U-ED-LSTM_pub/src/notebooks/evaluation_run_notebooks/normal_4layer/Helpdesk/../../../../model/dropout_uncertainty_enc_dec_LSTM/dropout_uncertainty_encoder.py:79\u001b[39m, in \u001b[36mDropoutUncertaintyLSTMEncoder.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m     77\u001b[39m \u001b[38;5;66;03m# Pass through the remaining LSTM cell: Layer gets for: input: h_n Tensor, hx: (h, c)\u001b[39;00m\n\u001b[32m     78\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m _, layer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(\u001b[38;5;28mself\u001b[39m.hidden_layers):\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m     outputs, (h, c), _ = \u001b[43mlayer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m=\u001b[49m\u001b[43moutputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhx\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mh\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mz\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m (h, c)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/XAI-Probabilistic_Suffix_Prediction_U-ED-L-p9C7deWr/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/XAI-Probabilistic_Suffix_Prediction_U-ED-L-p9C7deWr/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/IdeaProjects/XAI-Probabilistic_Suffix_Prediction_U-ED-LSTM_pub/src/notebooks/evaluation_run_notebooks/normal_4layer/Helpdesk/../../../../model/dropout_uncertainty_enc_dec_LSTM/dropout_uncertainty_LSTM_cell.py:196\u001b[39m, in \u001b[36mDropoutUncertaintyLSTMCell.forward\u001b[39m\u001b[34m(self, input, hx, z)\u001b[39m\n\u001b[32m    194\u001b[39m i = torch.sigmoid(\u001b[38;5;28mself\u001b[39m.Wi(x_i) + \u001b[38;5;28mself\u001b[39m.Ui(h_i))\n\u001b[32m    195\u001b[39m \u001b[38;5;66;03m# Forget gate: Which information from previous step is kept and which thrown away\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m196\u001b[39m f = torch.sigmoid(\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mWf\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_f\u001b[49m\u001b[43m)\u001b[49m + \u001b[38;5;28mself\u001b[39m.Uf(h_f))\n\u001b[32m    197\u001b[39m c_tilde = torch.tanh(\u001b[38;5;28mself\u001b[39m.Wc(x_c) + \u001b[38;5;28mself\u001b[39m.Uc(h_c))\n\u001b[32m    198\u001b[39m o = torch.sigmoid(\u001b[38;5;28mself\u001b[39m.Wo(x_o) + \u001b[38;5;28mself\u001b[39m.Uo(h_o))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/XAI-Probabilistic_Suffix_Prediction_U-ED-L-p9C7deWr/lib/python3.12/site-packages/torch/nn/modules/module.py:1775\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1773\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1774\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1775\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/XAI-Probabilistic_Suffix_Prediction_U-ED-L-p9C7deWr/lib/python3.12/site-packages/torch/nn/modules/module.py:1786\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1781\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1782\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1783\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1784\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1785\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1786\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1788\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1789\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/.local/share/virtualenvs/XAI-Probabilistic_Suffix_Prediction_U-ED-L-p9C7deWr/lib/python3.12/site-packages/torch/nn/modules/linear.py:134\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    130\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m    131\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    132\u001b[39m \u001b[33;03m    Runs the forward pass.\u001b[39;00m\n\u001b[32m    133\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m134\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "\n",
    "def save_chunk(results, i):\n",
    "    chunk_number = (i + 1)\n",
    "    filename = os.path.join(output_dir, f'results_part_{chunk_number:03d}.pkl')\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(f\"Saved {len(results)} results to {filename}\")\n",
    "\n",
    "output_dir = '../../../../../../../evaluation_results/Helpdesk'\n",
    "\n",
    "save_every = 10\n",
    "\n",
    "results = {}\n",
    "for i, (case_name, prefix_len, prefix, predicted_suffixes, suffix, mean_prediction) in enumerate(new_eval.evaluate(random_order=True)):\n",
    "    assert((case_name, prefix_len) not in results)\n",
    "    results[(case_name, prefix_len)] = (prefix, suffix, mean_prediction, predicted_suffixes)\n",
    "    print(prefix_len, len(suffix))\n",
    "    if (i + 1) % save_every == 0:\n",
    "        save_chunk(results, i)\n",
    "        results = {}\n",
    "\n",
    "if len(results):\n",
    "    save_chunk(results, i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "XAI-Probabilistic_Suffix_Prediction_U-ED-L-p9C7deWr",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
