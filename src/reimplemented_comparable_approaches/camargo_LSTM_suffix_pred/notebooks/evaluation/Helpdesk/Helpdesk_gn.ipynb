{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:36:58.268268Z",
     "iopub.status.busy": "2025-04-24T06:36:58.264093Z",
     "iopub.status.idle": "2025-04-24T06:36:59.642674Z",
     "shell.execute_reply": "2025-04-24T06:36:59.642159Z"
    }
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import os\n",
    "import torch\n",
    "from tqdm.notebook import tqdm\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "sys.path.insert(0, '..')\n",
    "sys.path.insert(0, '../..')\n",
    "sys.path.insert(0, '../../..')\n",
    "sys.path.insert(0, '../../../..')\n",
    "sys.path.insert(0, '../../../../..')\n",
    "sys.path.insert(0, '../../../../../..')\n",
    "\n",
    "from joinLSTM.model import FullShared_Join_LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-04-24T06:36:59.644768Z",
     "iopub.status.busy": "2025-04-24T06:36:59.644530Z",
     "iopub.status.idle": "2025-04-24T06:37:00.418119Z",
     "shell.execute_reply": "2025-04-24T06:37:00.416631Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data set categories:  ([('Activity', 16, {'Assign seriousness': 1, 'Closed': 2, 'Create SW anomaly': 3, 'DUPLICATE': 4, 'EOS': 5, 'INVALID': 6, 'Insert ticket': 7, 'RESOLVED': 8, 'Require upgrade': 9, 'Resolve SW anomaly': 10, 'Resolve ticket': 11, 'Schedule intervention': 12, 'Take in charge ticket': 13, 'VERIFIED': 14, 'Wait': 15}), ('Resource', 24, {'EOS': 1, 'Value 1': 2, 'Value 10': 3, 'Value 11': 4, 'Value 12': 5, 'Value 13': 6, 'Value 14': 7, 'Value 15': 8, 'Value 16': 9, 'Value 17': 10, 'Value 18': 11, 'Value 19': 12, 'Value 2': 13, 'Value 20': 14, 'Value 21': 15, 'Value 22': 16, 'Value 3': 17, 'Value 4': 18, 'Value 5': 19, 'Value 6': 20, 'Value 7': 21, 'Value 8': 22, 'Value 9': 23})], [('case_elapsed_time', 1, {})])\n",
      "Model input features:  [['Activity', 'Resource'], ['case_elapsed_time']]\n",
      "\n",
      "\n",
      "Embeddings:  ModuleList(\n",
      "  (0): Embedding(16, 8)\n",
      "  (1): Embedding(24, 9)\n",
      ")\n",
      "Total embedding feature size:  17\n",
      "Input feature size:  18\n",
      "Cells hidden size:  50\n",
      "Number of LSTM layer:  1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/LordKunkler/.local/share/virtualenvs/PrimePPM-tDGhFIeG/lib/python3.13/site-packages/torch/nn/modules/rnn.py:123: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.2 and num_layers=1\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#load model\n",
    "file_path_model = '../../training/Helpdesk/Helpdesk_camargo_act_1_suffix_length5.pkl'\n",
    "\n",
    "model = FullShared_Join_LSTM.load(file_path_model)\n",
    "\n",
    "# Load the dataset\n",
    "file_path_data_set = '../../../../../../encoded_data/compare_camargo/helpdesk_all_5_test.pkl'\n",
    "helpdesk_test_dataset = torch.load(file_path_data_set, weights_only=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Global placeholders for multiprocessing workers\n",
    "\n",
    "# Model\n",
    "global_model = None\n",
    "# Number of samples\n",
    "global_samples_per_case = None\n",
    "# Categorical categories, tensors:\n",
    "global_cat_categories = None\n",
    "# Global scaler params for case_elapsed_time\n",
    "global_scaler_params = None\n",
    "#\n",
    "global_dict_cat_class_id = None\n",
    "\n",
    "def init_worker(model: FullShared_Join_LSTM,\n",
    "                samples_per_case: int,\n",
    "                cat_categories,\n",
    "                scaler_params,\n",
    "                dict_cat_class_ids,\n",
    "                ):\n",
    "    \"\"\"\n",
    "    Initializer for each worker process, setting global variables.\n",
    "    \"\"\"\n",
    "    global global_model, global_samples_per_case, global_cat_categories, global_scaler_params, global_dict_cat_class_id\n",
    "    \n",
    "    # Models have already been moved to CPU before forking\n",
    "    model.eval()\n",
    "    \n",
    "    global_model = model\n",
    "    global_samples_per_case = samples_per_case\n",
    "    global_cat_categories = cat_categories\n",
    "    global_scaler_params = scaler_params\n",
    "    global_dict_cat_class_id = dict_cat_class_ids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def iterate_case(full_case: Tuple[List[torch.Tensor], List[torch.Tensor]],\n",
    "                 concept_name_id: int,\n",
    "                 min_suffix_size: int):\n",
    "    \n",
    "    cats_full, nums_full, _ = full_case\n",
    "    seq_len = cats_full[0].size(0)\n",
    "    window_size = seq_len - min_suffix_size\n",
    "\n",
    "    # Initialize with all‐zero padding, batch dim = 1\n",
    "    cats_prefix: List[torch.Tensor] = [torch.zeros((1, window_size), dtype=cat.dtype) for cat in cats_full]\n",
    "    nums_prefix: List[torch.Tensor] = [torch.zeros((1, window_size), dtype=num.dtype) for num in nums_full]\n",
    "\n",
    "    prefix_length = 0\n",
    "\n",
    "    # Slide the window one event at a time\n",
    "    for i in range(window_size):\n",
    "        # Roll left by 1 and insert the new event at the rightmost slot\n",
    "        for j, cat_stream in enumerate(cats_full):\n",
    "            cats_prefix[j][0] = torch.roll(cats_prefix[j][0], shifts=-1, dims=0)\n",
    "            cats_prefix[j][0, -1] = cat_stream[i]\n",
    "\n",
    "        for j, num_stream in enumerate(nums_full):\n",
    "            nums_prefix[j][0] = torch.roll(nums_prefix[j][0], shifts=-1, dims=0)\n",
    "            nums_prefix[j][0, -1] = num_stream[i]\n",
    "\n",
    "        # Only start yielding once we've seen at least one real “activity” token\n",
    "        if prefix_length > 0 or cats_prefix[concept_name_id][0, -1] != 0:\n",
    "            prefix_length += 1\n",
    "            \n",
    "            yield prefix_length, (cats_prefix, nums_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def _evaluate_case(case_name: str,\n",
    "                   full_case: Tuple[List[torch.Tensor], List[torch.Tensor], str],\n",
    "                   concept_name_id: int,\n",
    "                   min_suffix_size: int,\n",
    "                   ):\n",
    "\n",
    "    # List of tensors for test samples:\n",
    "    cats_full, nums_full, _ = full_case\n",
    "    # Denormalization values for numerical variables:\n",
    "    mean_s, std_s = global_scaler_params\n",
    "    \n",
    "    act2idx, res2idx = global_dict_cat_class_id  # expect tuple of two dicts\n",
    "    # Invert them:\n",
    "    idx2act = {ix:name for name, ix in act2idx.items() }\n",
    "    idx2res = {ix:name for name, ix in res2idx.items() }\n",
    "\n",
    "    results = []\n",
    "    # iterate_case already defined elsewhere\n",
    "    for prefix_length, (cats_pref, nums_pref) in iterate_case(full_case, concept_name_id, min_suffix_size):\n",
    "\n",
    "        # prefix_prep\n",
    "        acts = cats_pref[0][0].tolist()\n",
    "        ress = cats_pref[1][0].tolist()\n",
    "        times = nums_pref[0][0].tolist()\n",
    "        # Build the prefix\n",
    "        prefix_prep = [{\"Activity\": idx2act[a], \"Resource\": idx2res[r], \"case_elapsed_time\": t * std_s + mean_s} for a, r, t in zip(acts, ress, times) if a != 0]\n",
    "\n",
    "        # true target: Get from the activity full tensor all indices of the last n values which are not zero\n",
    "        non_zero_ids = (cats_full[0] != 0).nonzero(as_tuple=True)[0]\n",
    "        \n",
    "        # Get the activity ids without the EOS:\n",
    "        true_acts = cats_full[0][(non_zero_ids[0]+prefix_length):-1].tolist()\n",
    "        true_ress = cats_full[1][(non_zero_ids[0]+prefix_length):-1].tolist()\n",
    "        true_nums = nums_full[0][(non_zero_ids[0]+prefix_length):-1].tolist()\n",
    "        \n",
    "        # Build target as list of dicts:\n",
    "        target = [{\"Activity\": idx2act[a]} for a in true_acts if idx2act[a] != \"EOS\"]\n",
    "        if target == []:\n",
    "            continue\n",
    "\n",
    "        # MOST LIKELY\n",
    "        cats_pref_clone = [t.clone() for t in cats_pref]\n",
    "        # print(cats_pref_clone)\n",
    "        nums_pref_clone = [t.clone() for t in nums_pref]\n",
    "        ml_list = []\n",
    "        # Iterate through window size - pref len:\n",
    "        for i in range(len(cats_pref[0][0])-prefix_length):\n",
    "            # Predictions\n",
    "            act_probs = global_model((cats_pref_clone, nums_pref_clone))\n",
    "            # Index of most likely prediction\n",
    "            index_act = act_probs.argmax(dim=-1).item()\n",
    "            \n",
    "            # NaN is predicted new value at positon 0\n",
    "            if index_act == 0:\n",
    "                act = 'NaN'\n",
    "            \n",
    "            #  Stop the suffix creation if EOS is predicted\n",
    "            elif idx2act[index_act] == 'EOS':\n",
    "                break\n",
    "            \n",
    "            else:\n",
    "                act = idx2act[index_act]\n",
    "            \n",
    "            # Add to Most-likely:\n",
    "            ml_list.append({\"Activity\": act})\n",
    "                        \n",
    "            # Update Prefix Most Likely\n",
    "            cats_pref_clone[0] = torch.cat([cats_pref_clone[0][:, 1:], torch.tensor([[index_act]])], dim=1)\n",
    "            if i < len(true_acts):\n",
    "                cats_pref_clone[1] = torch.cat([cats_pref_clone[1][:, 1:], torch.tensor([[true_ress[i]]])], dim=1)\n",
    "                nums_pref_clone[0] = torch.cat([nums_pref_clone[0][:, 1:], torch.tensor([[true_nums[i]]])], dim=1)\n",
    "                \n",
    "        most_likely = ml_list\n",
    "        \n",
    "        # RANDOM SAMPLING\n",
    "        samples_lists = []\n",
    "        for _ in range(global_samples_per_case):\n",
    "            cats_pref_clone_samples = [t.clone() for t in cats_pref]\n",
    "            nums_pref_clone_samples = [t.clone() for t in nums_pref]\n",
    "            # Iterate through window size - pref len:\n",
    "            samples = []\n",
    "            for i in range(len(cats_pref[0][0])-prefix_length):\n",
    "                # Predictions\n",
    "                act_probs_sample = global_model((cats_pref_clone_samples, nums_pref_clone_samples)).squeeze(0)              \n",
    "                # Ranodm Smapling:\n",
    "                random_index_act = torch.multinomial(act_probs_sample, num_samples=1).item()    \n",
    "                \n",
    "                # NaN is predicted new value at positon 0\n",
    "                if random_index_act == 0:\n",
    "                   act = 'NaN'\n",
    "                \n",
    "                #  Stop the suffix creation if EOS is predicted\n",
    "                elif idx2act[random_index_act] == 'EOS':\n",
    "                    break\n",
    "                \n",
    "                else:\n",
    "                    act = idx2act[random_index_act]\n",
    "                \n",
    "                samples.append({\"Activity\": act })\n",
    "                \n",
    "                # Update Prefix Most Likely\n",
    "                cats_pref_clone_samples[0] = torch.cat([cats_pref_clone_samples[0][:, 1:], torch.tensor([[random_index_act]])], dim=1)\n",
    "                if i < len(true_acts):\n",
    "                    cats_pref_clone_samples[1] = torch.cat([cats_pref_clone_samples[1][:, 1:], torch.tensor([[true_ress[i]]])], dim=1)\n",
    "                    nums_pref_clone_samples[0] = torch.cat([nums_pref_clone_samples[0][:, 1:], torch.tensor([[true_nums[i]]])], dim=1)\n",
    "            \n",
    "            samples_lists.append(samples)\n",
    "            \n",
    "        random_suffixes = samples_lists\n",
    "\n",
    "        results.append((case_name, prefix_length, prefix_prep, random_suffixes, target, most_likely))\n",
    "        \n",
    "        # print(\"Case Name: \", case_name)\n",
    "        # print(\"Prefix length: \", prefix_length)\n",
    "        # print(\"Prefix prepared: \", prefix_prep)\n",
    "        # print(\"Random Suffixes: \", random_suffixes)\n",
    "        # print(\"Target: \", target)\n",
    "        # print(\"Most Likely: \", most_likely)\n",
    "\n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_seq_processing(model: FullShared_Join_LSTM,\n",
    "                            dataset,\n",
    "                            device,\n",
    "                            samples_per_case: int = 1000,\n",
    "                            random_order: Optional[bool]= False,\n",
    "                            ):\n",
    "    \"\"\"\n",
    "    Sequential evaluation yielding tuples per case and prefix length.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Move models to CPU\n",
    "    model.to('cpu')\n",
    "    \n",
    "    # Category names and ids\n",
    "    concept_name = 'Activity'\n",
    "    # Id of activity in cat list\n",
    "    concept_name_id = [i for i, cat in enumerate(helpdesk_test_dataset.all_categories[0]) if cat[0] == concept_name][0]\n",
    "    \n",
    "    # Dict with key: act class, value: index position\n",
    "    act_classes_id =  helpdesk_test_dataset.all_categories[0][0][2]\n",
    "    # Dict with key: res class, value: index position\n",
    "    res_classes_id =  helpdesk_test_dataset.all_categories[0][1][2]\n",
    "    \n",
    "    # Id of EOS token in activity\n",
    "    eos_value = 'EOS'\n",
    "    # index of EOS value in activity dict:\n",
    "    eos_id = [v for k, v in helpdesk_test_dataset.all_categories[0][concept_name_id][2].items() if k == eos_value][0]\n",
    "    \n",
    "    cases = {}\n",
    "    for event in dataset:\n",
    "        # Get suffix being the last \n",
    "        suffix = event[0][concept_name_id][-dataset.encoder_decoder.min_suffix_size:]\n",
    "        if torch.all(suffix  == eos_id).item():\n",
    "            cases[event[2]] = event\n",
    "            \n",
    "    case_items = list(cases.items())\n",
    "    if random_order:\n",
    "        case_items = random.sample(case_items, len(case_items))\n",
    "    \n",
    "    # Tuple of category (e.g., Activity) with amount classes, dict with class and index\n",
    "    cat_categories, _ = model.data_set_categories\n",
    "    # print(cat_categories)\n",
    "    \n",
    "    # Scaler used in dataset to normalize/ denormalize the numerical attributes:\n",
    "    scaler = dataset.encoder_decoder.continuous_encoders['case_elapsed_time']\n",
    "    scaler_params = (scaler.mean_.item(), scaler.scale_.item())\n",
    "    \n",
    "    # Initialize globals for identical logic\n",
    "    init_worker(model, samples_per_case, cat_categories, scaler_params, (act_classes_id, res_classes_id))\n",
    "    \n",
    "    # for cats, nums, case_name in tqdm(cases, total=len(cases)):\n",
    "    for _, (case_name, full_case) in tqdm(enumerate(case_items), total=len(cases)):\n",
    "        \n",
    "        # Get a list with the results for all cases of one case:\n",
    "        results = _evaluate_case(case_name=case_name,\n",
    "                                 full_case=full_case,\n",
    "                                 concept_name_id=concept_name_id,\n",
    "                                 min_suffix_size=dataset.encoder_decoder.min_suffix_size)\n",
    "        \n",
    "        # Return the results for inserting:\n",
    "        for res in results:\n",
    "            yield res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_dir = '../../../../../../../../data/Helpdesk/eval_camargo_sl5/'\n",
    "\n",
    "def save_chunk(results, i):\n",
    "    chunk_number = (i + 1)\n",
    "    filename = os.path.join(output_dir, f'results_part_{chunk_number:03d}.pkl')\n",
    "    with open(filename, 'wb') as f:\n",
    "        pickle.dump(results, f)\n",
    "    print(f\"Saved {len(results)} results to {filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 13/535 [00:59<56:12,  6.46s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_050.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 27/535 [01:43<26:42,  3.15s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_100.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 43/535 [02:27<25:38,  3.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_150.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 55/535 [03:12<26:52,  3.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_200.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▏        | 66/535 [04:06<36:31,  4.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_250.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 81/535 [04:51<22:10,  2.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_300.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 94/535 [05:40<29:38,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_350.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 107/535 [06:26<24:08,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_400.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 121/535 [07:15<27:33,  3.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_450.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 135/535 [07:58<19:55,  2.99s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_500.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 148/535 [08:42<20:21,  3.16s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_550.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 162/535 [09:29<24:32,  3.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_600.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 175/535 [10:17<25:13,  4.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_650.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 190/535 [11:00<16:09,  2.81s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_700.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 205/535 [11:47<16:13,  2.95s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_750.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 217/535 [12:37<28:38,  5.40s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_800.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 232/535 [13:20<14:42,  2.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_850.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 247/535 [14:05<13:39,  2.84s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_900.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 48%|████▊     | 259/535 [14:52<18:50,  4.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_950.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 272/535 [15:40<15:39,  3.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1000.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 284/535 [16:26<16:38,  3.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1050.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 298/535 [17:10<13:29,  3.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1100.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 58%|█████▊    | 312/535 [17:54<11:15,  3.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1150.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████▏   | 328/535 [18:45<13:54,  4.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1200.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▎   | 341/535 [19:26<08:09,  2.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1250.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 356/535 [20:11<10:05,  3.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1300.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 371/535 [20:57<08:22,  3.06s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1350.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 387/535 [21:39<06:20,  2.57s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1400.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 402/535 [22:24<07:05,  3.20s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1450.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 416/535 [23:13<07:34,  3.82s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1500.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 430/535 [24:02<05:54,  3.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1550.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 442/535 [24:51<05:05,  3.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1600.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 455/535 [25:38<03:40,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1650.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 470/535 [26:26<03:49,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1700.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 483/535 [27:11<02:23,  2.75s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1750.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 497/535 [27:59<03:18,  5.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1800.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▌| 509/535 [28:45<01:31,  3.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1850.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 98%|█████████▊| 523/535 [29:33<00:36,  3.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 50 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1900.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 535/535 [30:12<00:00,  3.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 46 results to ../../../../../../../../data/Helpdesk/eval_camargo_sl5/results_part_1946.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Is set to four in the method parameters -> call if change\n",
    "num_processes=16\n",
    "\n",
    "save_every = 50\n",
    "\n",
    "results = {}\n",
    "\n",
    "for i, (case_name, prefix_len, prefix, sampled_cets, target_cet, mean_cet) in enumerate(evaluate_seq_processing(model=model,\n",
    "                                                                                                                dataset=helpdesk_test_dataset,\n",
    "                                                                                                                device = torch.device(\"cpu\"),\n",
    "                                                                                                                samples_per_case=1000)\n",
    "                                                                                                                ):\n",
    "\n",
    "# for i, (case_name, prefix_len, prefix, sampled_cets, target_cet, mean_cet) in enumerate(evaluate_parallel_processing(model=model,\n",
    "#                                                                                                                      dataset=helpdesk_test_dataset,\n",
    "#                                                                                                                      samples_per_case=1000,\n",
    "#                                                                                                                      processes=num_processes)):\n",
    "\n",
    "    # print(case_name, prefix_len)\n",
    "    # if (case_name != '1016'):\n",
    "    #    break\n",
    "    \n",
    "    assert((case_name, prefix_len) not in results)\n",
    "    \n",
    "    results[(case_name, prefix_len)] = (prefix, target_cet, mean_cet, sampled_cets)\n",
    "    \n",
    "    if (i + 1) % save_every == 0:\n",
    "        save_chunk(results, i)\n",
    "        results = {}\n",
    "\n",
    "if len(results):\n",
    "    save_chunk(results, i)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PrimePPM-tDGhFIeG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "0f1e5fa1289a4973aee01a132fadb2e5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "18fbee425ac74dffbe02d1fde657909a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "2c4d1639a2f54154b0de587dcb0272ef": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_39f7f482327a467bb8783c1e45ed2e63",
       "placeholder": "​",
       "style": "IPY_MODEL_3d2f3c820a964a63b10ebc5839383c13",
       "tabbable": null,
       "tooltip": null,
       "value": "100%"
      }
     },
     "39f7f482327a467bb8783c1e45ed2e63": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "3d2f3c820a964a63b10ebc5839383c13": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "background": null,
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "48b687d9bde44d8b94f60131ff03a7e4": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HTMLModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HTMLView",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_8972ab140e62469383d81f5f9a0b322c",
       "placeholder": "​",
       "style": "IPY_MODEL_18fbee425ac74dffbe02d1fde657909a",
       "tabbable": null,
       "tooltip": null,
       "value": " 535/535 [52:16&lt;00:00,  6.61s/it]"
      }
     },
     "65c54b4ee754446a87489889e33bed7f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "76473ba04feb461d929b58538bb8f313": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "FloatProgressModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "ProgressView",
       "bar_style": "success",
       "description": "",
       "description_allow_html": false,
       "layout": "IPY_MODEL_65c54b4ee754446a87489889e33bed7f",
       "max": 535,
       "min": 0,
       "orientation": "horizontal",
       "style": "IPY_MODEL_ffc6385fe6594114ace93c0ba03781bd",
       "tabbable": null,
       "tooltip": null,
       "value": 535
      }
     },
     "8972ab140e62469383d81f5f9a0b322c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {
       "_model_module": "@jupyter-widgets/base",
       "_model_module_version": "2.0.0",
       "_model_name": "LayoutModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "LayoutView",
       "align_content": null,
       "align_items": null,
       "align_self": null,
       "border_bottom": null,
       "border_left": null,
       "border_right": null,
       "border_top": null,
       "bottom": null,
       "display": null,
       "flex": null,
       "flex_flow": null,
       "grid_area": null,
       "grid_auto_columns": null,
       "grid_auto_flow": null,
       "grid_auto_rows": null,
       "grid_column": null,
       "grid_gap": null,
       "grid_row": null,
       "grid_template_areas": null,
       "grid_template_columns": null,
       "grid_template_rows": null,
       "height": null,
       "justify_content": null,
       "justify_items": null,
       "left": null,
       "margin": null,
       "max_height": null,
       "max_width": null,
       "min_height": null,
       "min_width": null,
       "object_fit": null,
       "object_position": null,
       "order": null,
       "overflow": null,
       "padding": null,
       "right": null,
       "top": null,
       "visibility": null,
       "width": null
      }
     },
     "9be34aa604f54b8eb8d02b837bf975a2": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "_dom_classes": [],
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "HBoxModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/controls",
       "_view_module_version": "2.0.0",
       "_view_name": "HBoxView",
       "box_style": "",
       "children": [
        "IPY_MODEL_2c4d1639a2f54154b0de587dcb0272ef",
        "IPY_MODEL_76473ba04feb461d929b58538bb8f313",
        "IPY_MODEL_48b687d9bde44d8b94f60131ff03a7e4"
       ],
       "layout": "IPY_MODEL_0f1e5fa1289a4973aee01a132fadb2e5",
       "tabbable": null,
       "tooltip": null
      }
     },
     "ffc6385fe6594114ace93c0ba03781bd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "_model_module": "@jupyter-widgets/controls",
       "_model_module_version": "2.0.0",
       "_model_name": "ProgressStyleModel",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "2.0.0",
       "_view_name": "StyleView",
       "bar_color": null,
       "description_width": ""
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
